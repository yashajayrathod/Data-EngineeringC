{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO92i/Wnebr8T6dYjm1NA2P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashajayrathod/Data-EngineeringC/blob/main/ConstructiveIQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_qoz4qe7s3k"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.metrics.pairwise import euclidean_distances"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# Assuming materials.csv is uploaded, read the file\n",
        "materials = pd.read_csv('materials.csv')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "0-CxPcu87xQt",
        "outputId": "f8a3cf70-f80a-4c1c-8146-a58559a767ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-84fd809f-8995-4dde-b42d-f2a2e95852f0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-84fd809f-8995-4dde-b42d-f2a2e95852f0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving materials.csv to materials (4).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(materials.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbRHFqIHGBby",
        "outputId": "c1b5d47d-dd2a-40c6-b476-42d70565c530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "test_pairs = pd.read_csv('test_pairs.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "jhNqk8RHExTw",
        "outputId": "b8bb5560-931d-46ad-957e-6086ce0ac5ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-04bbdcbc-6e10-4c88-a133-531b555cb78e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-04bbdcbc-6e10-4c88-a133-531b555cb78e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test_pairs.csv to test_pairs (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(test_pairs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnFQJa14-RLk",
        "outputId": "8b8c89d7-d533-47b5-9175-cf40bf634324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1wGHJFQcF0P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the dataset\n",
        "print(\"First few rows of materials dataset:\")\n",
        "print(materials.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq119GKd8QRz",
        "outputId": "dee4219b-6a34-44fc-a1f7-a5752e39f17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of materials dataset:\n",
            "   ID                               Material_Description\n",
            "0   1  INSULATION GASKET KIT - 2\" - 300# - DOUBLE COM...\n",
            "1   2  ASSEMBLY COMPRESSOR - 10\" - 150# - HOT DIP GAL...\n",
            "2   3  SPUR GEAR PINION SHAFT - 10\" - 150# - SCH.XS A...\n",
            "3   4  SUCTION HEADER - 6\" - 600# - HOT DIP GALVANIZE...\n",
            "4   5  MOVABLE STOOL - 6\" - 150# - DUAL CERTIFIED, DR...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Exploration: Check for null values\n",
        "print(\"\\nChecking for missing values in the dataset:\")\n",
        "print(materials.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zykntusm8tF1",
        "outputId": "0d2dcdd6-8855-424e-c118-6b65b4be42bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking for missing values in the dataset:\n",
            "ID                      0\n",
            "Material_Description    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Preprocessing\n",
        "\n",
        "# Convert material descriptions to lowercase\n",
        "materials['clean_description'] = materials['Material_Description'].str.lower()\n",
        "\n",
        "# Remove punctuation and special characters\n",
        "materials['clean_description'] = materials['clean_description'].apply(lambda x: re.sub(r'[^a-z\\s]', '', x))\n"
      ],
      "metadata": {
        "id": "CK66Gt7Y9DIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK packages for tokenization and lemmatization\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize the WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Tokenize and lemmatize the words\n",
        "materials['clean_description'] = materials['clean_description'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(x)]))\n",
        "\n",
        "# Show cleaned data\n",
        "print(\"\\nCleaned material descriptions:\")\n",
        "print(materials[['Material_Description', 'clean_description']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhw7Fy-09XUi",
        "outputId": "bb6285c8-3eb6-4a35-ac3d-4df73877e310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaned material descriptions:\n",
            "                                Material_Description  \\\n",
            "0  INSULATION GASKET KIT - 2\" - 300# - DOUBLE COM...   \n",
            "1  ASSEMBLY COMPRESSOR - 10\" - 150# - HOT DIP GAL...   \n",
            "2  SPUR GEAR PINION SHAFT - 10\" - 150# - SCH.XS A...   \n",
            "3  SUCTION HEADER - 6\" - 600# - HOT DIP GALVANIZE...   \n",
            "4  MOVABLE STOOL - 6\" - 150# - DUAL CERTIFIED, DR...   \n",
            "\n",
            "                                   clean_description  \n",
            "0  insulation gasket kit double compression with ...  \n",
            "1  assembly compressor hot dip galvanized drawing...  \n",
            "2  spur gear pinion shaft schxs astm a grb seamle...  \n",
            "3  suction header hot dip galvanized drawing no p...  \n",
            "4   movable stool dual certified drawing no prjr iso  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization using TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
        "tfidf = TfidfVectorizer(lowercase=True, stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(materials['clean_description'])\n",
        "\n",
        "# Show the shape of the TF-IDF matrix\n",
        "print(\"\\nShape of the TF-IDF matrix:\")\n",
        "print(tfidf_matrix.shape)\n",
        "\n",
        "# Optional: You can print feature names (the vocabulary learned by TF-IDF)\n",
        "print(\"\\nTF-IDF Feature Names (first 10):\")\n",
        "print(tfidf.get_feature_names_out()[:10])\n",
        "\n",
        "# Optionally, show a sample of the TF-IDF matrix\n",
        "print(\"\\nSample of the TF-IDF matrix (first 5 rows):\")\n",
        "print(tfidf_matrix[:5].toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzU6yyta9r5n",
        "outputId": "f2ee3f03-ee2b-4b58-c5ca-6bc4d85541b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of the TF-IDF matrix:\n",
            "(1000, 58)\n",
            "\n",
            "TF-IDF Feature Names (first 10):\n",
            "['air' 'asme' 'assembly' 'astm' 'ball' 'barrel' 'bellow' 'cable'\n",
            " 'certified' 'compression']\n",
            "\n",
            "Sample of the TF-IDF matrix (first 5 rows):\n",
            "[[0.         0.19046231 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.35428813 0.         0.\n",
            "  0.         0.         0.27562829 0.11136349 0.         0.\n",
            "  0.         0.         0.39556824 0.         0.         0.\n",
            "  0.         0.         0.35428813 0.         0.         0.39556824\n",
            "  0.         0.         0.39556824 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.17137213 0.35428813\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.2266565  0.40406494 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.50550954 0.\n",
            "  0.         0.39609103 0.         0.13252626 0.         0.\n",
            "  0.         0.39609103 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.39609103 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.20393855 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.39166425 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.10413964 0.         0.\n",
            "  0.         0.         0.         0.25505561 0.37680798 0.\n",
            "  0.26051396 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.37680798 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.3267975  0.         0.3267975  0.25156944\n",
            "  0.         0.         0.37680798 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.2128299  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.3382656  0.         0.11317872 0.         0.\n",
            "  0.         0.3382656  0.         0.         0.         0.\n",
            "  0.         0.41107515 0.         0.3382656  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.30488299 0.         0.30488299 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.27340508\n",
            "  0.         0.         0.         0.         0.         0.41107515\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.45566042 0.         0.         0.\n",
            "  0.         0.         0.         0.136669   0.45566042 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.32196416 0.         0.         0.50828567 0.\n",
            "  0.         0.         0.         0.         0.2103136  0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.39977706 0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Word2Vec Embeddings ---\n",
        "# Tokenize descriptions\n",
        "materials['tokenized_description'] = materials['clean_description'].apply(lambda x: word_tokenize(x))\n",
        "\n",
        "# Train Word2Vec model\n",
        "w2v_model = Word2Vec(sentences=materials['tokenized_description'], vector_size=100, window=5, min_count=1)\n",
        "# Print a sample of word vectors\n",
        "print(\"\\nWord vector for 'steel':\")\n",
        "print(w2v_model.wv['steel'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZU3lGHfAnJw",
        "outputId": "a0dd1c71-ef51-4332-cd30-cb01ee781a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word vector for 'steel':\n",
            "[-1.52885616e-02  6.64749295e-02 -4.21601087e-02  6.72345757e-02\n",
            " -1.00404605e-01 -2.93692470e-01  1.70459256e-01  3.74528557e-01\n",
            " -1.92792013e-01 -3.27101052e-01  2.73630116e-02 -2.45969102e-01\n",
            "  8.56357347e-03  1.43906370e-01  9.05815586e-02 -1.20122954e-01\n",
            "  1.67572901e-01 -9.61685851e-02 -4.75215167e-02 -3.08807820e-01\n",
            "  2.10382059e-01 -1.41951302e-02  2.60401815e-01 -1.11829080e-01\n",
            "  2.17747569e-04 -2.35064290e-02 -2.12124616e-01  2.94731949e-02\n",
            " -6.73388094e-02  3.85196544e-02  1.51961699e-01 -3.73749733e-02\n",
            "  2.13348731e-01 -3.72431755e-01  4.86928038e-03  1.33517191e-01\n",
            "  5.96144088e-02  3.74537669e-02 -1.43242285e-01 -9.43176076e-02\n",
            "  1.53755695e-02 -1.19382642e-01  6.05836092e-03  3.01628504e-02\n",
            "  9.51964259e-02 -1.23749427e-01 -1.59930199e-01 -9.79817286e-02\n",
            "  1.33164540e-01  1.12259433e-01  1.00482002e-01 -1.30778760e-01\n",
            " -9.06372592e-02 -1.17707863e-01  4.57572155e-02 -7.23674595e-02\n",
            "  1.33563653e-01 -9.27082077e-02 -6.28456846e-02  4.01346385e-02\n",
            "  2.11280379e-02 -1.42641202e-01  1.80552363e-01  8.90738145e-02\n",
            " -1.52071252e-01  2.91573644e-01 -5.39294928e-02  1.59795791e-01\n",
            " -3.18690121e-01  1.40903622e-01 -3.99228856e-02  1.34888768e-01\n",
            "  2.40068018e-01  4.01703492e-02  3.04247439e-01 -6.29424080e-02\n",
            "  9.11937952e-02  5.26394211e-02 -8.45054761e-02  3.60022001e-02\n",
            " -2.31100738e-01  2.39404701e-02 -1.62409171e-01  1.82882518e-01\n",
            " -1.21661805e-01 -1.83156401e-01  1.86138168e-01  4.74495180e-02\n",
            "  9.89735425e-02  1.06672771e-01  2.96060413e-01  1.44084636e-02\n",
            "  1.78420991e-02 -8.50480236e-03  2.72136122e-01  6.56420290e-02\n",
            " -4.31822129e-02 -3.20684686e-02 -9.63246897e-02 -1.93048529e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the average word2vec vector for a description\n",
        "def get_avg_word2vec(tokens, model, vector_size):\n",
        "    # Return the average of all word vectors for words in the tokens list\n",
        "    vec = np.zeros(vector_size)\n",
        "    count = 0\n",
        "    for word in tokens:\n",
        "        if word in model.wv:\n",
        "            vec += model.wv[word]\n",
        "            count += 1\n",
        "    if count > 0:\n",
        "        vec /= count\n",
        "    return vec\n",
        "\n",
        "# Create an array of average Word2Vec vectors for each material description\n",
        "vector_size = w2v_model.vector_size\n",
        "avg_w2v_vectors = np.array([get_avg_word2vec(desc, w2v_model, vector_size) for desc in materials['tokenized_description']])\n",
        "\n",
        "# Show the shape of the Word2Vec vector matrix\n",
        "print(\"Word2Vec matrix shape:\", avg_w2v_vectors.shape)\n",
        "\n",
        "# Optionally, display the first few averaged vectors\n",
        "print(\"\\nSample of averaged Word2Vec vectors (first 5):\")\n",
        "print(avg_w2v_vectors[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0xm0hskCLyu",
        "outputId": "a192eba8-cd67-4bd1-8dd3-dacfbbfafae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec matrix shape: (1000, 100)\n",
            "\n",
            "Sample of averaged Word2Vec vectors (first 5):\n",
            "[[-0.01841371  0.06735764 -0.0510124   0.05793531 -0.09912897 -0.29787587\n",
            "   0.18722055  0.3905565  -0.20040448 -0.32707486  0.0320042  -0.24411822\n",
            "   0.00301199  0.1449091   0.07415974 -0.13921215  0.18685052 -0.10044854\n",
            "  -0.06661959 -0.32749226  0.20919403 -0.01993958  0.28275068 -0.12535955\n",
            "  -0.00641657 -0.04614534 -0.21308315  0.02368523 -0.0886104   0.04238924\n",
            "   0.1712152  -0.04505572  0.22843935 -0.37953155 -0.00273505  0.13798612\n",
            "   0.05039443  0.04325749 -0.13049625 -0.1153054   0.00259891 -0.12707146\n",
            "   0.01576783  0.03730688  0.10414253 -0.12476447 -0.16717905 -0.10554431\n",
            "   0.1477737   0.12236704  0.0919294  -0.13399137 -0.08968    -0.13652571\n",
            "   0.04665227 -0.08687657  0.14661095 -0.09055839 -0.07131308  0.04441106\n",
            "   0.04303614 -0.15246347  0.19146341  0.07934599 -0.17050284  0.30182057\n",
            "  -0.05127768  0.16770494 -0.33238961  0.13880662 -0.03231328  0.13670196\n",
            "   0.25365197  0.05078916  0.32878884 -0.07654631  0.10017193  0.05820018\n",
            "  -0.09284225  0.02611939 -0.22803015  0.0205991  -0.18744748  0.205427\n",
            "  -0.12085942 -0.2037605   0.18923928  0.05056209  0.09781543  0.10948919\n",
            "   0.303061    0.02051164  0.03559292 -0.01707824  0.287366    0.0741923\n",
            "  -0.04365804 -0.03365988 -0.10153818 -0.03891446]\n",
            " [-0.02004959  0.06200951 -0.04888767  0.05978753 -0.09383093 -0.28739951\n",
            "   0.17819161  0.37857176 -0.19216321 -0.31717425  0.03072901 -0.24348985\n",
            "  -0.00233276  0.14445018  0.07617123 -0.13628856  0.17340343 -0.0951928\n",
            "  -0.06056705 -0.3138627   0.20532356 -0.02072307  0.27089271 -0.11835376\n",
            "  -0.00216399 -0.03783293 -0.20139892  0.02490286 -0.0858999   0.03715271\n",
            "   0.16095045 -0.04848001  0.21957451 -0.36738397 -0.00191216  0.13396792\n",
            "   0.05015908  0.04154175 -0.12799088 -0.1096227   0.00434008 -0.12356248\n",
            "   0.014429    0.04272127  0.10507119 -0.11485891 -0.16641553 -0.09953387\n",
            "   0.1453881   0.11889284  0.08686891 -0.12880148 -0.07992635 -0.12924566\n",
            "   0.04365714 -0.08307313  0.14322443 -0.09088644 -0.06568051  0.04449409\n",
            "   0.0391749  -0.14311788  0.18267087  0.07758586 -0.16182975  0.2891985\n",
            "  -0.04844366  0.1738471  -0.31395776  0.13585605 -0.02639658  0.13222719\n",
            "   0.24846253  0.05170282  0.32040239 -0.06839036  0.09858686  0.05809715\n",
            "  -0.08548903  0.01927603 -0.22740265  0.01639541 -0.17983352  0.1901984\n",
            "  -0.11473524 -0.19316857  0.18436895  0.04058137  0.09290813  0.10301883\n",
            "   0.2928903   0.02531125  0.03768629 -0.01447785  0.27802636  0.08195017\n",
            "  -0.04387256 -0.03492578 -0.0963292  -0.03259633]\n",
            " [-0.01809213  0.06200174 -0.04916515  0.06256614 -0.10046536 -0.29035767\n",
            "   0.18524074  0.3793436  -0.19361684 -0.32421286  0.03405694 -0.2394225\n",
            "  -0.00208596  0.14025514  0.0800171  -0.13842642  0.17404042 -0.09826182\n",
            "  -0.06582139 -0.31684239  0.20252115 -0.01739219  0.2766186  -0.12154983\n",
            "  -0.00734541 -0.0419491  -0.20331365  0.01762824 -0.08613811  0.04055163\n",
            "   0.16396033 -0.04924553  0.22654882 -0.36571501 -0.0062188   0.1365913\n",
            "   0.04569188  0.04489421 -0.12801596 -0.11512904  0.00819464 -0.11823119\n",
            "   0.01542208  0.03674971  0.10321899 -0.11521851 -0.16550146 -0.09845827\n",
            "   0.1457597   0.11869608  0.08962866 -0.13668054 -0.08273996 -0.12662673\n",
            "   0.03784866 -0.08364887  0.14565181 -0.0938358  -0.067062    0.03925785\n",
            "   0.03924921 -0.14172001  0.18772286  0.07076681 -0.16665554  0.29823012\n",
            "  -0.05428119  0.16578104 -0.32931902  0.12975262 -0.03079245  0.14033202\n",
            "   0.25258196  0.05084611  0.32316815 -0.07047035  0.09967851  0.0600522\n",
            "  -0.09326848  0.01990378 -0.22466878  0.01728767 -0.18404556  0.19350438\n",
            "  -0.1178632  -0.19730651  0.18249232  0.04117673  0.09232638  0.10446973\n",
            "   0.292858    0.0268777   0.02991016 -0.00946468  0.2842484   0.07503833\n",
            "  -0.04971524 -0.03698189 -0.09718293 -0.03292877]\n",
            " [-0.01957518  0.06277536 -0.04601633  0.05614009 -0.09462392 -0.28219772\n",
            "   0.17760078  0.36928671 -0.18789316 -0.31297483  0.03011385 -0.23800924\n",
            "  -0.00510965  0.13770151  0.0759281  -0.13312771  0.1686867  -0.09316592\n",
            "  -0.05919833 -0.30877799  0.20109244 -0.01691082  0.26704924 -0.11552269\n",
            "  -0.00418572 -0.03632278 -0.19941976  0.01928301 -0.08267106  0.03820738\n",
            "   0.15832601 -0.04789773  0.21738298 -0.35778785 -0.00238204  0.13176852\n",
            "   0.04559341  0.04104474 -0.12520789 -0.10997992  0.00589805 -0.11994948\n",
            "   0.01408766  0.0387742   0.10120687 -0.1140859  -0.16421784 -0.09866469\n",
            "   0.14071568  0.11577479  0.0863864  -0.12963895 -0.07729309 -0.12487509\n",
            "   0.0430801  -0.08134826  0.14257527 -0.08952265 -0.06528086  0.04264578\n",
            "   0.03608311 -0.1414925   0.17879405  0.07250309 -0.15819171  0.28483611\n",
            "  -0.04908757  0.16574896 -0.31177873  0.12818475 -0.03054368  0.13303976\n",
            "   0.24348416  0.04847901  0.31397578 -0.06723439  0.09809788  0.0555782\n",
            "  -0.0877237   0.0214148  -0.22097899  0.01553639 -0.17565352  0.18954876\n",
            "  -0.11273458 -0.18798816  0.17889301  0.03912831  0.08877205  0.1021663\n",
            "   0.28776778  0.02607472  0.03154016 -0.01598325  0.27328878  0.07904882\n",
            "  -0.04417172 -0.03481122 -0.09371363 -0.02936671]\n",
            " [-0.01775354  0.05961301 -0.04874352  0.05926346 -0.09658117 -0.28838263\n",
            "   0.18106033  0.37599089 -0.18884861 -0.32224706  0.03619765 -0.24137732\n",
            "  -0.00359762  0.13919398  0.07635794 -0.13324477  0.1788094  -0.09503601\n",
            "  -0.06363775 -0.31212868  0.20628581 -0.01765904  0.27431782 -0.12137508\n",
            "  -0.00275747 -0.03657001 -0.20150944  0.02292359 -0.08483171  0.04275358\n",
            "   0.15698549 -0.04495487  0.22296037 -0.37209262 -0.00561399  0.13120031\n",
            "   0.04781328  0.04063763 -0.13073542 -0.10646512  0.00553764 -0.11779198\n",
            "   0.01783712  0.03767201  0.10519784 -0.11553423 -0.16112641 -0.10096094\n",
            "   0.14256086  0.12138578  0.09060825 -0.1285455  -0.0792272  -0.13317184\n",
            "   0.03884034 -0.08456276  0.14250513 -0.08364899 -0.06672504  0.04508864\n",
            "   0.03818779 -0.14482062  0.18181591  0.07592553 -0.16247948  0.29191948\n",
            "  -0.05451434  0.16729965 -0.31891152  0.13203202 -0.03054479  0.13053322\n",
            "   0.24776262  0.04781428  0.31514638 -0.07307561  0.09913365  0.06002707\n",
            "  -0.08924355  0.02167104 -0.22732938  0.01895627 -0.1792411   0.18990043\n",
            "  -0.11402155 -0.19226968  0.18834242  0.04320698  0.09152527  0.09928101\n",
            "   0.29126788  0.0193584   0.03038741 -0.01121598  0.27803013  0.07675603\n",
            "  -0.04547692 -0.03793393 -0.10051338 -0.03190316]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cosine similarity between all TF-IDF vectors\n",
        "cosine_sim_matrix = cosine_similarity(tfidf_matrix)\n"
      ],
      "metadata": {
        "id": "JgYl3n9lCpkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Define function to retrieve Cosine Similarity for pairs\n",
        "def get_cosine_similarity(id1, id2, similarity_matrix):\n",
        "    return similarity_matrix[id1-1, id2-1]  # Assuming IDs are 1-based, arrays are 0-based\n",
        "\n"
      ],
      "metadata": {
        "id": "Y5yQ0TQsIga7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Create a mapping from material ID to the row index in materials.csv\n",
        "id_to_index = {id: idx for idx, id in enumerate(materials['ID'])}\n",
        "\n",
        "# Step 7: Update the get_cosine_similarity function to handle index lookup\n",
        "def get_cosine_similarity(id1, id2, similarity_matrix, id_to_index):\n",
        "    try:\n",
        "        index1 = id_to_index[id1]\n",
        "        index2 = id_to_index[id2]\n",
        "        return similarity_matrix[index1, index2]\n",
        "    except KeyError:\n",
        "        # If the ID is not found in the id_to_index mapping, return a default similarity (e.g., 0)\n",
        "        return 0.0\n",
        "\n",
        "# Step 8: Apply Cosine Similarity on the test pairs using the updated function\n",
        "test_pairs['Similarity_Score'] = test_pairs.apply(lambda row: get_cosine_similarity(row['ID_1'], row['ID_2'], cosine_sim_matrix, id_to_index), axis=1)\n",
        "\n",
        "# Step 9: Preview the result\n",
        "print(test_pairs.head())\n",
        "\n",
        "# Step 10: Save results to a submission CSV\n",
        "test_pairs[['ID_1', 'ID_2', 'Similarity_Score']].to_csv('submission.csv', index=False)\n",
        "\n",
        "# Download the submission file\n",
        "files.download('submission.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "9Zd2RxsCIssP",
        "outputId": "e71336af-b08a-4f96-c3de-9c9e12819b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID_1  ID_2  Similarity_Score\n",
            "0   375   932          0.076284\n",
            "1   588    22          0.055578\n",
            "2   876   724          0.014835\n",
            "3   270   154          0.197916\n",
            "4   512   544          0.048491\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_413055ca-7fb3-4641-8672-dde3f39a6ef0\", \"submission.csv\", 13925)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries for Jaccard Similarity\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "# Function to calculate Jaccard similarity between two material descriptions (bag of words approach)\n",
        "def get_jaccard_similarity(id1, id2, materials):\n",
        "    set1 = set(materials.loc[materials['ID'] == id1, 'Material_Description'].values[0].split())\n",
        "    set2 = set(materials.loc[materials['ID'] == id2, 'Material_Description'].values[0].split())\n",
        "    return len(set1.intersection(set2)) / len(set1.union(set2))\n",
        "\n",
        "# Apply Jaccard similarity for each test pair\n",
        "test_pairs['Jaccard_Similarity'] = test_pairs.apply(lambda row: get_jaccard_similarity(row['ID_1'], row['ID_2'], materials), axis=1)\n",
        "\n",
        "# Preview the results\n",
        "print(test_pairs[['ID_1', 'ID_2', 'Jaccard_Similarity']].head())\n",
        "\n",
        "# Save Jaccard results to a CSV (optional)\n",
        "test_pairs[['ID_1', 'ID_2', 'Jaccard_Similarity']].to_csv('jaccard_submission.csv', index=False)\n",
        "files.download('jaccard_submission.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "HOc3gB82Krpi",
        "outputId": "70625907-02b4-42a2-80f3-241b4f94ce2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID_1  ID_2  Jaccard_Similarity\n",
            "0   375   932            0.136364\n",
            "1   588    22            0.192308\n",
            "2   876   724            0.153846\n",
            "3   270   154            0.217391\n",
            "4   512   544            0.115385\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e400e02a-4c68-46ad-aa74-d3fb5963e811\", \"jaccard_submission.csv\", 11777)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a mapping from material ID to the row index in materials.csv\n",
        "id_to_index = {id: idx for idx, id in enumerate(materials['ID'])}\n",
        "\n",
        "# Step 2: Define the function to retrieve Euclidean distance for pairs\n",
        "def get_euclidean_distance(id1, id2, distance_matrix, id_to_index):\n",
        "    try:\n",
        "        index1 = id_to_index[id1]\n",
        "        index2 = id_to_index[id2]\n",
        "        return distance_matrix[index1, index2]\n",
        "    except KeyError:\n",
        "        # If the ID is not found, return a default distance (e.g., high distance)\n",
        "        return np.inf  # or return a specific value like 1.0 or some other default\n",
        "\n",
        "# Step 3: Apply Euclidean Distance on the test pairs\n",
        "test_pairs['Euclidean_Distance'] = test_pairs.apply(\n",
        "    lambda row: get_euclidean_distance(row['ID_1'], row['ID_2'], euclidean_dist_matrix, id_to_index),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Step 4: Preview the result\n",
        "print(test_pairs[['ID_1', 'ID_2', 'Euclidean_Distance']].head())\n",
        "\n",
        "# Optionally save the Euclidean Distance results to a CSV\n",
        "test_pairs[['ID_1', 'ID_2', 'Euclidean_Distance']].to_csv('euclidean_submission.csv', index=False)\n",
        "files.download('euclidean_submission.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "OD2MDpb6Nlnd",
        "outputId": "4ecfc78f-f30e-47ca-f654-4f964a0d7e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID_1  ID_2  Euclidean_Distance\n",
            "0   375   932            1.359203\n",
            "1   588    22            1.374352\n",
            "2   876   724            1.403684\n",
            "3   270   154            1.266558\n",
            "4   512   544            1.379499\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b44c674f-7f5e-430b-b9a1-a8b4b0f6867d\", \"euclidean_submission.csv\", 13287)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check available columns in materials DataFrame\n",
        "print(materials.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niG_04doQxgs",
        "outputId": "550981f7-406d-4159-f49d-0826ca33f8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'Material_Description', 'Description_Length', 'Count_steel',\n",
            "       'Count_plastic', 'Count_copper', 'Similarity_Score'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Feature Engineering\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the training data\n",
        "materials = pd.read_csv('materials.csv')\n",
        "\n",
        "# Calculate additional features\n",
        "materials['Description_Length'] = materials['Material_Description'].apply(len)\n",
        "\n",
        "# Optional: Count specific material-related terms (example: \"steel\", \"plastic\")\n",
        "specific_terms = ['steel', 'plastic', 'aluminum']\n",
        "for term in specific_terms:\n",
        "    materials[f'Count_{term}'] = materials['Material_Description'].str.lower().str.count(term)\n",
        "\n",
        "# Load test pairs\n",
        "test_pairs = pd.read_csv('test_pairs.csv')\n",
        "\n",
        "# Create a function to get features for each pair\n",
        "def create_features(pair):\n",
        "    id1, id2 = pair['ID_1'], pair['ID_2']\n",
        "    desc1 = materials.loc[materials['ID'] == id1, 'Material_Description'].values[0]\n",
        "    desc2 = materials.loc[materials['ID'] == id2, 'Material_Description'].values[0]\n",
        "\n",
        "    features = {\n",
        "        'Description_Length_1': len(desc1),\n",
        "        'Description_Length_2': len(desc2),\n",
        "        'Similarity_Score': get_cosine_similarity(id1, id2, cosine_sim_matrix, id_to_index)\n",
        "    }\n",
        "\n",
        "    for term in specific_terms:\n",
        "        features[f'Count_{term}_1'] = desc1.lower().count(term)\n",
        "        features[f'Count_{term}_2'] = desc2.lower().count(term)\n",
        "\n",
        "    return pd.Series(features)\n",
        "\n",
        "# Step 2: Prepare dataset for modeling\n",
        "features_df = test_pairs.apply(create_features, axis=1)\n",
        "\n",
        "# Combine features with similarity score for the training phase\n",
        "# You should have a target variable for training; assuming it's available in materials\n",
        "# For demonstration, we use a random similarity score as the target\n",
        "# Replace this with your actual target variable for training\n",
        "y = np.random.rand(len(features_df))  # Replace with actual similarity scores if available\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_df, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train a RandomForest model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Predict similarity scores on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "\n",
        "# Step 5: Predict similarity scores for the actual test pairs\n",
        "# Use the same features created earlier\n",
        "predictions = model.predict(features_df)\n",
        "\n",
        "# Add predictions to the test_pairs DataFrame\n",
        "test_pairs['Predicted_Similarity_Score'] = predictions\n",
        "\n",
        "# Step 6: Save the results to a submission file\n",
        "test_pairs[['ID_1', 'ID_2', 'Predicted_Similarity_Score']].to_csv('enhanced_submission.csv', index=False)\n",
        "\n",
        "# Download the enhanced submission file\n",
        "from google.colab import files\n",
        "files.download('enhanced_submission.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "PfyW0H70QZrj",
        "outputId": "a6611610-514f-451b-9024-e480db0d5ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.11372899068798402\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5e56c33f-0721-480e-8730-fd7e477b846c\", \"enhanced_submission.csv\", 13494)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Step 2: Load the Test Pairs and Predicted Scores\n",
        "# Load your test pairs\n",
        "test_pairs = pd.read_csv('test_pairs.csv')  # Ensure the path is correct\n",
        "\n",
        "# Example: Predicted similarity scores (you should replace this with your actual predictions)\n",
        "# Let's say these are your predictions\n",
        "predicted_similarity_scores = np.random.rand(len(test_pairs))  # Replace with your actual predicted scores\n",
        "test_pairs['Predicted_Similarity_Score'] = predicted_similarity_scores\n",
        "\n",
        "# Step 3: Load True Labels for Test Pairs\n",
        "# Replace this with the actual ground truth labels\n",
        "# For example, let's create some dummy true labels for demonstration\n",
        "# Assuming we have some ground truth similarities for the pairs\n",
        "# Ensure true_labels has the same length as test_pairs\n",
        "true_labels = np.random.randint(0, 2, size=len(test_pairs))  # Replace with actual labels\n",
        "\n",
        "# Step 4: Define Average Precision Function\n",
        "def average_precision(y_true, y_pred, k):\n",
        "    top_k_indices = np.argsort(y_pred)[::-1][:k]  # Indices of the top K predictions (descending order)\n",
        "    correct_predictions = 0\n",
        "    ap = 0.0\n",
        "\n",
        "    for i, idx in enumerate(top_k_indices):\n",
        "        if y_true[idx] == 1:  # Assuming 1 indicates a similar pair\n",
        "            correct_predictions += 1\n",
        "            ap += correct_predictions / (i + 1)  # Precision at rank i + 1\n",
        "\n",
        "    return ap / min(k, np.sum(y_true)) if np.sum(y_true) > 0 else 0.0\n",
        "\n",
        "# Step 5: Define MAP@K Function\n",
        "def mean_average_precision_at_k(test_pairs, true_labels, k):\n",
        "    map_k = 0.0\n",
        "    num_queries = len(test_pairs)\n",
        "\n",
        "    for i in range(num_queries):\n",
        "        y_true_pair = true_labels # Access the true label for the current pair\n",
        "        y_pred_pair = test_pairs['Predicted_Similarity_Score'].values[i] # Access the prediction for the current pair\n",
        "        map_k += average_precision(y_true_pair, y_pred_pair, k)\n",
        "\n",
        "    return map_k / num_queries\n",
        "\n",
        "# Step 6: Set the value of K for evaluation\n",
        "k = 5  # You can change this to any desired value\n",
        "\n",
        "# Step 7: Calculate MAP@K\n",
        "map_k = mean_average_precision_at_k(test_pairs, true_labels, k)\n",
        "\n",
        "# Step 8: Print the MAP@K Result\n",
        "print(f'Mean Average Precision at {k}: {map_k}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzosebP6POOO",
        "outputId": "8e3d32c5-e99f-40af-8980-67dc178ff619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Average Precision at 5: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the test pairs\n",
        "test_pairs = pd.read_csv('test_pairs.csv')\n",
        "\n",
        "# Generate random similarity scores between 0 and 1\n",
        "test_pairs['Similarity_Score'] = np.random.rand(len(test_pairs))\n",
        "\n",
        "# Save the submission file\n",
        "test_pairs[['ID_1', 'ID_2', 'Similarity_Score']].to_csv('submission.csv', index=False)\n",
        "\n",
        "# Print confirmation\n",
        "print(\"Submission file 'submission.csv' created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm8wxMcyTTc4",
        "outputId": "f5f8fc8b-6611-4acd-b3f7-ebaa95c642be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file 'submission.csv' created successfully.\n"
          ]
        }
      ]
    }
  ]
}